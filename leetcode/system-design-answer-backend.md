# LeetCode (Online Judge) - System Design Answer (Backend Focus)

*45-minute system design interview format - Backend Engineer Position*

---

## ðŸŽ¯ Problem Statement

Design the backend infrastructure for an online coding practice and evaluation platform that allows users to:
- Browse and solve coding problems
- Submit code in multiple programming languages
- Execute user code securely in sandboxed environments
- Validate outputs against test cases with resource limits
- Track progress and maintain leaderboards

---

## ðŸ“‹ Requirements Clarification

### Functional Requirements

1. **Problem Management**: CRUD operations for coding problems with descriptions, test cases, constraints
2. **Code Submission**: Accept code in multiple languages (Python, JavaScript, Java, C++)
3. **Sandboxed Execution**: Run untrusted code safely with resource limits
4. **Test Validation**: Compare outputs against expected results with tolerance for formatting
5. **User Progress**: Track solved problems, attempts, best runtime per user
6. **Leaderboards**: Rankings by problems solved and performance metrics

### Non-Functional Requirements

1. **Security**: Sandboxed execution preventing system access, network calls, resource exhaustion
2. **Latency**: Results within 5 seconds for simple problems, 15 seconds for complex
3. **Fairness**: Consistent evaluation across all users and submissions
4. **Scale**: Support 100K concurrent users, 10K submissions/minute during contests

### Scale Estimates

- 10 million registered users
- 500K daily active users
- Normal: 1M submissions/day = 12/second
- Contest peak: 10K submissions/minute = 170/second
- Average execution time: 2 seconds
- Concurrent executions needed at peak: ~340

---

## ðŸ—ï¸ High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Load Balancer (nginx)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼               â–¼               â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ API Server  â”‚ â”‚ API Server  â”‚ â”‚ API Server  â”‚
            â”‚   (Node)    â”‚ â”‚   (Node)    â”‚ â”‚   (Node)    â”‚
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                   â”‚               â”‚               â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                      â”‚                      â”‚
            â–¼                      â–¼                      â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  PostgreSQL  â”‚      â”‚    Kafka     â”‚      â”‚    Valkey    â”‚
    â”‚  (Primary)   â”‚      â”‚  (Submission â”‚      â”‚   (Cache +   â”‚
    â”‚              â”‚      â”‚    Queue)    â”‚      â”‚   Sessions)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â–¼                     â–¼                     â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Judge Workerâ”‚      â”‚ Judge Workerâ”‚       â”‚ Judge Workerâ”‚
    â”‚  (Python)   â”‚      â”‚   (Java)    â”‚       â”‚   (C++)     â”‚
    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚      â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚       â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
    â”‚ â”‚ gVisor  â”‚ â”‚      â”‚ â”‚ gVisor  â”‚ â”‚       â”‚ â”‚ gVisor  â”‚ â”‚
    â”‚ â”‚ Sandbox â”‚ â”‚      â”‚ â”‚ Sandbox â”‚ â”‚       â”‚ â”‚ Sandbox â”‚ â”‚
    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚      â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚       â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ”’ Deep Dive: Sandboxed Code Execution

### Security Requirements

User code is untrusted. We must prevent:
1. **System access**: Reading files, executing commands
2. **Network access**: Making external requests
3. **Resource exhaustion**: Infinite loops, memory bombs
4. **Process escape**: Breaking out of sandbox

### Sandbox Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Host Machine                                  â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    Container Runtime (gVisor)                   â”‚ â”‚
â”‚  â”‚                                                                 â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚                 Sandbox Container                         â”‚  â”‚ â”‚
â”‚  â”‚  â”‚                                                           â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”‚              User Process                           â”‚  â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”‚                                                     â”‚  â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  - No network access                                â”‚  â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  - Read-only filesystem                             â”‚  â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  - No fork/exec beyond limits                       â”‚  â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  - Memory limit: 256MB                              â”‚  â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  - CPU limit: 2 seconds                             â”‚  â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  - No /proc, /sys access                            â”‚  â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚ â”‚
â”‚  â”‚  â”‚                                                           â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  Seccomp: Whitelist of allowed syscalls                   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  AppArmor: Mandatory access control                       â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚                                                                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                      â”‚
â”‚  cgroups: Resource limits enforced at kernel level                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Trade-off 1: gVisor vs Docker vs Firecracker

| Approach | Pros | Cons |
|----------|------|------|
| âœ… gVisor | Strong isolation, syscall filtering, user-space kernel | 10-20% performance overhead |
| âŒ Docker alone | Simple, fast startup, wide tooling support | Shared kernel, escape vulnerabilities |
| âŒ Firecracker | VM-level isolation, used by AWS Lambda | 125MB memory per VM, 150ms cold start |

> "I chose gVisor over plain Docker or Firecracker for code execution sandboxing. Docker containers share the host kernel, so a kernel exploit could escape the sandboxâ€”this happened with CVE-2019-5736 where a malicious container could overwrite the host runc binary. For an online judge running arbitrary user code, kernel-level vulnerabilities are unacceptable. Firecracker provides true VM isolation but adds 125MB memory overhead per microVM and 150ms cold startâ€”with 340 concurrent executions at peak, that's 42GB just for VM overhead, plus we'd need to pre-warm VMs extensively to hide latency. gVisor runs a user-space kernel (called Sentry) that intercepts syscalls and reimplements them safely. A kernel exploit in user code can only compromise Sentry, not the host. The trade-off is 10-20% execution slowdown, but since we control the time limits, we adjust multipliers per language to compensate. For the specific threat model of untrusted code execution, gVisor's syscall-level isolation is the right balance of security and performance."

### Security Configuration Layers

| Layer | Configuration | Purpose |
|-------|---------------|---------|
| Network | network_mode: none | Block all external requests |
| Filesystem | read_only: true | Prevent persistent changes |
| Capabilities | cap_drop: ALL | No privilege escalation |
| Memory | mem_limit: 256m | Prevent memory bombs |
| CPU | cpus: 0.5 | Limit compute usage |
| Processes | pids_limit: 50 | Prevent fork bombs |
| Privileges | no-new-privileges: true | Block privilege escalation |
| Seccomp | custom profile | Whitelist allowed syscalls |

---

## ðŸ”§ Deep Dive: Test Execution Strategy

### Trade-off 2: Sequential vs Parallel Test Execution

| Approach | Pros | Cons |
|----------|------|------|
| âœ… Sequential | Fair timing, predictable resources, early termination | Slower total time |
| âŒ Parallel | Faster completion, better throughput | Resource contention, unfair timing, no early exit |

> "I chose sequential test case execution over parallel execution, and this is a critical fairness decision. If we run 50 test cases in parallel, they compete for CPU and memoryâ€”a solution's measured runtime depends on what other test cases are doing simultaneously, introducing non-determinism. User A's submission might report 45ms while User B's identical code reports 62ms due to resource contention. For a platform where users compare runtimes and compete on leaderboards, this inconsistency destroys trust. Sequential execution ensures each test case runs in isolation with dedicated resources, producing reproducible timing. The trade-off is speed: 50 test cases at 100ms each take 5 seconds sequentially vs ~200ms parallel. But correctness and fairness trump speedâ€”users would rather wait 5 seconds for accurate results than get instant but unreliable measurements. Sequential also enables early termination: when a test fails, we stop immediately rather than wasting resources on remaining tests. For 'Wrong Answer' submissions (70% of failures), we often stop at test case 3 instead of running all 50."

### Test Execution Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Sequential Test Execution                       â”‚
â”‚                                                                  â”‚
â”‚  Test 1 â”€â”€â–¶ Run â”€â”€â–¶ Compare â”€â”€â–¶ PASS â”€â”€â–¶ Continue               â”‚
â”‚                                    â”‚                             â”‚
â”‚  Test 2 â”€â”€â–¶ Run â”€â”€â–¶ Compare â”€â”€â–¶ PASS â”€â”€â–¶ Continue               â”‚
â”‚                                    â”‚                             â”‚
â”‚  Test 3 â”€â”€â–¶ Run â”€â”€â–¶ Compare â”€â”€â–¶ FAIL â”€â”€â–¶ STOP (early exit)      â”‚
â”‚                                    â”‚                             â”‚
â”‚  Tests 4-50: Not executed (saved resources)                      â”‚
â”‚                                                                  â”‚
â”‚  Result: Wrong Answer on test 3 of 50                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Trade-off 3: Early Termination vs Run All Tests

| Approach | Pros | Cons |
|----------|------|------|
| âœ… Early termination (default) | Fast feedback, saves resources | Less debugging info |
| âŒ Run all tests | Shows all failures | Wastes resources, slower |

> "I chose early termination as the default, stopping execution on first failure. Most failed submissions fail earlyâ€”test case 1 catches syntax errors, test cases 2-5 catch basic logic bugs. Running all 50 tests for a submission that fails on test 3 wastes 47 test executions worth of resources. At 170 submissions/second during contests, this adds up quickly. Early termination also provides faster feedback: users see 'Wrong Answer on test 3' in 300ms instead of waiting 5 seconds for all tests. The trade-off is reduced debugging informationâ€”users don't know if their fix for test 3 will break test 47. We mitigate this with a 'Run All Tests' option for debugging, but charge it against a daily quota since it's resource-intensive. The default optimizes for the common case: fix one bug at a time, resubmit, iterate."

---

## ðŸ”§ Deep Dive: Worker Architecture

### Trade-off 4: Per-Language Workers vs Generic Workers

| Approach | Pros | Cons |
|----------|------|------|
| âœ… Per-language workers | Optimized containers, independent scaling, tuned limits | More infrastructure |
| âŒ Generic workers | Simpler ops, better utilization, fewer images | Cold starts, bloated containers |

> "I chose per-language worker pools over generic workers that handle all languages. A generic worker would need Python, Java, Node.js, GCC, Go, and Rust all installedâ€”creating a 2GB+ container image with long pull times and security surface area from unused runtimes. Per-language workers use minimal images: Python worker is 150MB, C++ worker is 200MB. This also enables language-specific tuning: Java workers get 512MB memory for JVM heap while Python gets 256MB. Most importantly, per-language pools enable independent scaling. Python represents 70% of submissions, so we run 5 Python workers vs 3 for other languages. During a contest with mostly Python submissions, we scale Python workers without wasting resources on idle Java workers. The trade-off is operational complexityâ€”we manage 6 worker deployments instead of 1â€”but Kubernetes makes this manageable, and the resource efficiency and cold-start improvements justify the complexity."

### Worker Pool Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Per-Language Worker Pools                    â”‚
â”‚                                                                  â”‚
â”‚  Kafka Topic: submissions.python                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  Python Workers (5)                                          â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”                    â”‚â”‚
â”‚  â”‚  â”‚ W1  â”‚ â”‚ W2  â”‚ â”‚ W3  â”‚ â”‚ W4  â”‚ â”‚ W5  â”‚   Image: 150MB     â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜   Memory: 256MB    â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                  â”‚
â”‚  Kafka Topic: submissions.java                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  Java Workers (3)                                            â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”                                     â”‚â”‚
â”‚  â”‚  â”‚ W1  â”‚ â”‚ W2  â”‚ â”‚ W3  â”‚               Image: 300MB          â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜               Memory: 512MB (JVM)   â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                  â”‚
â”‚  Scaling: Workers scale independently based on queue depth       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ”§ Deep Dive: Queue-Based Processing

### Trade-off 5: Kafka vs RabbitMQ vs Redis Streams

| Approach | Pros | Cons |
|----------|------|------|
| âœ… Kafka | Log retention, replay, consumer groups, high throughput | Operational complexity, higher latency |
| âŒ RabbitMQ | Lower latency, flexible routing, simpler ops | No replay, message loss on crash without confirms |
| âŒ Redis Streams | Simple, already have Redis, low latency | Limited durability, single-node bottleneck |

> "I chose Kafka over RabbitMQ or Redis Streams for submission queuing. The critical requirement is durability: a submission must never be lost, especially during rated contests where losing someone's accepted solution would be catastrophic. RabbitMQ can achieve durability with publisher confirms, persistent messages, and mirrored queuesâ€”but this configuration adds latency and complexity, and replay after a bug fix requires external tooling. Kafka's log-based architecture provides replay by default: if we discover our judge had a bug last week, we can reprocess all affected submissions from the log. Redis Streams would work for simple cases but lacks the partitioning and consumer group semantics needed for per-language worker pools. The trade-off is operational complexity: Kafka requires ZooKeeper (or KRaft), careful partition configuration, and more monitoring. But for a system where 'your submission was lost' is unacceptable, Kafka's durability guarantees are worth the operational investment. The per-language topics (submissions.python, submissions.java) enable independent scaling and prevent a Java backlog from blocking Python submissions."

### Message Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Server  â”‚      â”‚    Kafka     â”‚      â”‚   Worker     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                     â”‚                     â”‚
       â”‚  1. Create DB record (status: pending)    â”‚
       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶
       â”‚                     â”‚                     â”‚
       â”‚  2. Publish message â”‚                     â”‚
       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚                     â”‚
       â”‚                     â”‚                     â”‚
       â”‚  3. Return 202 + ID â”‚                     â”‚
       â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                     â”‚
       â”‚                     â”‚                     â”‚
       â”‚                     â”‚  4. Consume         â”‚
       â”‚                     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
       â”‚                     â”‚                     â”‚
       â”‚                     â”‚  5. Execute tests   â”‚
       â”‚                     â”‚  6. Update Valkey   â”‚
       â”‚                     â”‚  7. Commit offset   â”‚
       â”‚                     â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
       â”‚                     â”‚                     â”‚
       â”‚                     â”‚  8. Update DB       â”‚
       â”‚                     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
       â–¼                     â–¼                     â–¼
```

---

## ðŸ”§ Deep Dive: Output Comparison

### Trade-off 6: Strict vs Tolerant Output Matching

| Approach | Pros | Cons |
|----------|------|------|
| âœ… Tolerant (whitespace-normalized) | Fewer false negatives, better UX | Slightly more complex |
| âŒ Strict byte-for-byte | Simple implementation | Fails on trailing newlines, Windows line endings |
| âŒ Custom judger per problem | Handles any format | High maintenance, security risk |

> "I chose tolerant output matching with whitespace normalization over strict byte comparison. Strict matching rejects correct solutions due to trivial formatting differences: trailing newlines, Windows line endings (CRLF vs LF), trailing spaces on lines. Users submit 'Hello World\n' and get 'Wrong Answer' because expected output is 'Hello World'â€”this is frustrating and wastes support time. Our tolerant comparison normalizes both outputs: trim leading/trailing whitespace, convert CRLF to LF, remove trailing spaces per line, then compare. For floating-point problems, we accept relative error within 1e-6. The trade-off is that strictly-formatted problems (where whitespace matters) need explicit handling, and our comparison logic is more complex than strcmp(). For problems with multiple valid answers (like 'print any valid path'), we'd need custom judgersâ€”but these are rare (<5% of problems) and we implement them as trusted server-side code, not user-submitted. The default tolerant matching handles 95% of problems correctly while dramatically reducing false rejections."

### Output Comparison Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Output Comparison Pipeline                    â”‚
â”‚                                                                  â”‚
â”‚  User Output                    Expected Output                  â”‚
â”‚  "42\n"                         "42"                             â”‚
â”‚      â”‚                              â”‚                            â”‚
â”‚      â–¼                              â–¼                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  1. Trim leading/trailing whitespace                         â”‚â”‚
â”‚  â”‚  2. Normalize line endings (CRLF â†’ LF)                       â”‚â”‚
â”‚  â”‚  3. Remove trailing spaces per line                          â”‚â”‚
â”‚  â”‚  4. Handle floating point (if numeric, 1e-6 tolerance)       â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚      â”‚                              â”‚                            â”‚
â”‚      â–¼                              â–¼                            â”‚
â”‚  "42"                           "42"                             â”‚
â”‚      â”‚                              â”‚                            â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                     â–¼                                            â”‚
â”‚              Compare: MATCH âœ“                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ’¾ Data Model

### PostgreSQL Schema

**Problems Table**
- id (UUID, PK), title, slug (unique), description (TEXT)
- difficulty ('easy'/'medium'/'hard')
- time_limit_ms (default 2000), memory_limit_mb (default 256)
- created_at, updated_at

**Test Cases Table**
- id (UUID, PK), problem_id (FK â†’ problems, CASCADE DELETE)
- input (TEXT), expected_output (TEXT)
- is_sample (boolean, default false)
- order_index (integer)

**Submissions Table**
- id (UUID, PK), user_id (FK), problem_id (FK), contest_id (FK, nullable)
- language, code (TEXT), status (default 'pending')
- runtime_ms, memory_kb
- test_cases_passed, test_cases_total
- error_message (TEXT), created_at

**User Progress Table**
- user_id + problem_id (composite PK)
- status ('solved'/'attempted'/'unsolved')
- best_runtime_ms, best_memory_kb
- attempts (default 0), solved_at

### Why PostgreSQL?

| Consideration | PostgreSQL | MongoDB | Cassandra |
|---------------|------------|---------|-----------|
| ACID transactions | âœ… Full support | âš ï¸ Multi-doc overhead | âŒ No transactions |
| Complex queries | âœ… Full SQL | âš ï¸ Aggregation pipeline | âŒ Limited |
| Joins | âœ… Native | âš ï¸ $lookup (slow) | âŒ None |
| Horizontal scale | âš ï¸ Manual sharding | âœ… Built-in | âœ… Linear |

> "PostgreSQL wins because submission processing requires ACID: updating submission status and user progress must succeed or fail together. At 12 writes/second (normal load), a single PostgreSQL instance handles this trivially. When we need to scale, we shard by user_idâ€”each user's data stays on one shard, preserving transaction guarantees."

---

## ðŸš€ Caching Strategy

### Valkey Cache Layers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Valkey Cache                         â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  problem:{slug}           â”€â”€â–¶ Problem JSON (5 min)  â”‚ â”‚
â”‚  â”‚  problem:{slug}:tests     â”€â”€â–¶ Test cases (5 min)    â”‚ â”‚
â”‚  â”‚  submission:{id}:status   â”€â”€â–¶ Status JSON (5 min)   â”‚ â”‚
â”‚  â”‚  user:{id}:progress       â”€â”€â–¶ Progress JSON (1 min) â”‚ â”‚
â”‚  â”‚  leaderboard:global       â”€â”€â–¶ Top 100 users (1 min) â”‚ â”‚
â”‚  â”‚  session:{sid}            â”€â”€â–¶ Session data (7 days) â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> "Caching submission status in Valkey is critical for polling performance. With 10K concurrent users polling every second, that's 10K reads/second. Database queries at this rate would overwhelm PostgreSQL. Valkey handles 100K+ reads/second. Workers update status after each test case, enabling real-time progress display."

---

## ðŸŒ API Design

### RESTful Endpoints

```
POST   /api/v1/submissions       â”€â”€â–¶ Submit (returns 202 + ID)
GET    /api/v1/submissions/:id/status â”€â”€â–¶ Poll status (cached)
POST   /api/v1/submissions/run   â”€â”€â–¶ Run samples only (no record)

GET    /api/v1/problems          â”€â”€â–¶ List (paginated, filterable)
GET    /api/v1/problems/:slug    â”€â”€â–¶ Get details + sample tests

GET    /api/v1/users/progress    â”€â”€â–¶ Get solve progress
```

---

## âš–ï¸ Trade-offs Summary

| Decision | Choice | Trade-off |
|----------|--------|-----------|
| Sandbox | âœ… gVisor | 10-20% overhead vs kernel-level isolation |
| Test execution | âœ… Sequential | Slower vs fair, reproducible timing |
| Early termination | âœ… Stop on failure | Less debug info vs resource efficiency |
| Workers | âœ… Per-language pools | More infrastructure vs optimized scaling |
| Queue | âœ… Kafka | Complexity vs durability + replay |
| Output matching | âœ… Tolerant | Complexity vs fewer false rejections |
| Database | âœ… PostgreSQL | Manual sharding vs ACID + joins |

---

## ðŸ“ Closing Summary

> "I've designed a backend for an online judge with six key trade-off decisions: gVisor sandboxing for security without VM overhead, sequential test execution for fair timing, early termination for resource efficiency, per-language workers for optimized scaling, Kafka queuing for durability and replay, and tolerant output matching for better user experience. The unifying principle is that correctness and fairness trump performanceâ€”users trust our timing comparisons for leaderboards, so we sacrifice parallel execution speed for reproducible measurements. The async architecture with Kafka decouples API responsiveness from execution capacity, enabling independent scaling during contest bursts."
