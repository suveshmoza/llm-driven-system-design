# Web Crawler - System Design Answer (Full-Stack Focus)

*45-minute system design interview format - Full-Stack Engineer Position*

## ğŸ“‹ Introduction (2 minutes)

"I'll design a distributed web crawler with end-to-end integration. The full-stack challenge is connecting a high-throughput backend crawling system with a reactive monitoring dashboard. This requires:

1. **Backend complexity** - URL frontier, distributed workers, politeness enforcement
2. **Real-time frontend** - Live statistics and management controls
3. **Data flow** - URL discovery through processing to visualization
4. **Shared contracts** - Type safety across the entire system

Let me clarify requirements first."

---

## ğŸ¯ Requirements Clarification (5 minutes)

### Functional Requirements

"For the distributed crawler with monitoring dashboard:

1. **URL Discovery** - Extract links from pages, queue for crawling
2. **Distributed Crawling** - Workers fetch pages while respecting politeness
3. **Deduplication** - Avoid re-crawling duplicate URLs or content
4. **Admin Dashboard** - Real-time stats, domain management, seed URL control
5. **Worker Monitoring** - Health status and throughput visualization

I'll focus on end-to-end data flow, API contracts, and real-time communication."

### Non-Functional Requirements

| Requirement | Target | Rationale |
|-------------|--------|-----------|
| Scale | 10,000 pages/second | Distributed worker fleet |
| Dashboard Latency | < 2 seconds | Real-time monitoring |
| Worker Recovery | Graceful resume | Reliability |
| Operator Control | Full dashboard management | Usability |

---

## ğŸ—ï¸ High-Level Design (8 minutes)

### End-to-End Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Admin Dashboard (React)                          â”‚
â”‚   Real-time stats â”‚ URL frontier â”‚ Domain mgmt â”‚ Worker monitoring      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                           â”‚
                    â”‚ REST API                  â”‚ WebSocket
                    â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          API Server (Express)                            â”‚
â”‚   Routes: /api/urls, /api/domains, /api/workers, /api/stats             â”‚
â”‚   WebSocket: /ws/stats (real-time updates)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                           â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
        â–¼                       â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Coordinator  â”‚      â”‚    Workers    â”‚  â”‚ Stats Agg    â”‚
â”‚               â”‚â—„â”€â”€â”€â”€â–ºâ”‚   (1...N)     â”‚  â”‚              â”‚
â”‚ - Assignment  â”‚      â”‚ - Fetch pages â”‚  â”‚ - Metrics    â”‚
â”‚ - Scheduling  â”‚      â”‚ - Extract     â”‚  â”‚ - Broadcast  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL   â”‚      â”‚     Redis     â”‚      â”‚ Object Store  â”‚
â”‚               â”‚      â”‚               â”‚      â”‚               â”‚
â”‚ - URL frontierâ”‚      â”‚ - Bloom filterâ”‚      â”‚ - Page contentâ”‚
â”‚ - Crawl state â”‚      â”‚ - Rate limits â”‚      â”‚ - robots.txt  â”‚
â”‚ - Domain meta â”‚      â”‚ - Pub/Sub     â”‚      â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Integration Points

| Flow | Path | Purpose |
|------|------|---------|
| URL Submission | Dashboard â†’ API â†’ Frontier â†’ Worker â†’ Dashboard | Full lifecycle |
| Stats Streaming | Worker â†’ Redis Pub/Sub â†’ Stats Agg â†’ WebSocket â†’ Dashboard | Real-time metrics |
| Domain Control | Dashboard â†’ API â†’ Redis + PostgreSQL | Rate limit updates |

---

## ğŸ” Deep Dive: Shared Type Definitions (6 minutes)

### API Contract Types

Both frontend and backend share common type definitions for type safety.

**URL Frontier Entity:**

| Field | Type | Description |
|-------|------|-------------|
| id | number | Database primary key |
| url | string | Full URL to crawl |
| urlHash | string | SHA-256 for dedup |
| domain | string | Extracted hostname |
| priority | high/medium/low | Crawl priority |
| depth | number | Hops from seed |
| status | pending/processing/completed/failed | Current state |
| discoveredAt | timestamp | When found |
| scheduledAt | timestamp | When assigned |
| workerId | string | Assigned worker |

**Domain Entity:**

| Field | Type | Description |
|-------|------|-------------|
| id | number | Primary key |
| domain | string | Hostname |
| robotsTxt | string | Cached robots.txt |
| robotsFetchedAt | timestamp | Cache time |
| crawlDelayMs | number | Rate limit (ms) |
| lastCrawlAt | timestamp | Last fetch |
| totalPages | number | Pages crawled |
| avgResponseMs | number | Avg latency |
| isBlocked | boolean | Admin blocked |

**Worker Entity:**

| Field | Type | Description |
|-------|------|-------------|
| id | string | Worker UUID |
| status | active/idle/error | Current state |
| urlsProcessed | number | Total count |
| currentDomain | string | Active domain |
| uptimeSeconds | number | Time running |
| lastHeartbeat | timestamp | Health check |

**Real-Time Stats:**

| Field | Type | Description |
|-------|------|-------------|
| urlsPerSecond | number | Throughput |
| queueDepth | number | Pending URLs |
| activeWorkers | number | Active count |
| failedToday | number | Error count |
| totalCrawled | number | Total pages |
| byPriority | object | High/medium/low counts |

### Validation Rules

| Field | Validation | Error Code |
|-------|-----------|------------|
| urls (seed) | Array of valid URLs, 1-1000 items | VALIDATION_ERROR |
| priority | Enum: high, medium, low | VALIDATION_ERROR |
| crawlDelayMs | Number 500-60000 | VALIDATION_ERROR |
| isBlocked | Boolean | VALIDATION_ERROR |
| page | Number >= 1 | VALIDATION_ERROR |
| pageSize | Number 10-100 | VALIDATION_ERROR |

---

## ğŸ—ï¸ Deep Dive: End-to-End URL Submission Flow (10 minutes)

### URL Submission Sequence

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Dashboardâ”‚     â”‚   API    â”‚     â”‚  Bloom   â”‚     â”‚ Frontier â”‚     â”‚ WebSocketâ”‚
â”‚          â”‚     â”‚  Server  â”‚     â”‚  Filter  â”‚     â”‚    DB    â”‚     â”‚  Clients â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚                â”‚                â”‚                â”‚                â”‚
     â”‚ POST /urls/seedâ”‚                â”‚                â”‚                â”‚
     â”‚ [url1, url2...]â”‚                â”‚                â”‚                â”‚
     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                â”‚                â”‚                â”‚
     â”‚                â”‚                â”‚                â”‚                â”‚
     â”‚                â”‚  Validate with â”‚                â”‚                â”‚
     â”‚                â”‚  Zod schema    â”‚                â”‚                â”‚
     â”‚                â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚                â”‚                â”‚
     â”‚                â”‚        â”‚       â”‚                â”‚                â”‚
     â”‚                â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚                â”‚                â”‚
     â”‚                â”‚                â”‚                â”‚                â”‚
     â”‚                â”‚ Check each URL â”‚                â”‚                â”‚
     â”‚                â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                â”‚                â”‚
     â”‚                â”‚                â”‚                â”‚                â”‚
     â”‚                â”‚ not seen (new) â”‚                â”‚                â”‚
     â”‚                â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                â”‚                â”‚
     â”‚                â”‚                â”‚                â”‚                â”‚
     â”‚                â”‚                â”‚ INSERT batch   â”‚                â”‚
     â”‚                â”‚                â”‚ ON CONFLICT    â”‚                â”‚
     â”‚                â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º                â”‚
     â”‚                â”‚                â”‚                â”‚                â”‚
     â”‚                â”‚                â”‚ Mark URLs seen â”‚                â”‚
     â”‚                â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                â”‚                â”‚
     â”‚                â”‚                â”‚                â”‚                â”‚
     â”‚                â”‚                â”‚                â”‚ Broadcast      â”‚
     â”‚                â”‚                â”‚                â”‚ frontier-updateâ”‚
     â”‚                â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
     â”‚                â”‚                â”‚                â”‚                â”‚
     â”‚ 200 OK         â”‚                â”‚                â”‚                â”‚
     â”‚ {added: N}     â”‚                â”‚                â”‚                â”‚
     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                â”‚                â”‚                â”‚
```

### URL Normalization Steps

1. Parse URL with standard URL parser
2. Remove hash fragments
3. Normalize trailing slashes (remove except root)
4. Lowercase the entire URL
5. Compute SHA-256 hash for deduplication

### Seed URL Modal Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Add Seed URLs Modal               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚  URLs (one per line):                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ https://example.com                  â”‚   â”‚
â”‚  â”‚ https://example.com/page             â”‚   â”‚
â”‚  â”‚ https://other-site.com               â”‚   â”‚
â”‚  â”‚                                      â”‚   â”‚
â”‚  â”‚                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  3 URLs entered                             â”‚
â”‚                                             â”‚
â”‚  Priority:                                  â”‚
â”‚  â—‹ High   â— Medium   â—‹ Low                 â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ âœ“ Added 2 URLs (1 duplicate skipped)â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                             â”‚
â”‚           [Cancel]  [Add URLs]              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### API Client Design

| Endpoint | Method | Request | Response |
|----------|--------|---------|----------|
| /urls | GET | URLFilters | PaginatedResponse<FrontierURL> |
| /urls/seed | POST | AddSeedURLsRequest | {added, duplicates, message} |
| /urls/:id | DELETE | - | void |
| /domains | GET | page, pageSize | PaginatedResponse<Domain> |
| /domains/:domain | GET | - | Domain |
| /domains/:domain | PATCH | UpdateDomainRequest | Domain |
| /workers | GET | - | Worker[] |
| /stats | GET | - | CrawlStats |

---

## ğŸ“Š Deep Dive: Real-Time Stats with WebSocket (8 minutes)

### WebSocket Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        WebSocket Server                              â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Clients   â”‚    â”‚  Subscriber  â”‚    â”‚   Stats Aggregator     â”‚ â”‚
â”‚  â”‚   (Set)     â”‚â—„â”€â”€â”€â”‚   (Redis)    â”‚â—„â”€â”€â”€â”‚                        â”‚ â”‚
â”‚  â”‚             â”‚    â”‚              â”‚    â”‚ - Fetch from Redis     â”‚ â”‚
â”‚  â”‚ - Dashboard â”‚    â”‚ Subscribe:   â”‚    â”‚ - Pipeline queries     â”‚ â”‚
â”‚  â”‚   instances â”‚    â”‚ crawler:statsâ”‚    â”‚ - Combine metrics      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                                          â”‚                â”‚
â”‚         â”‚              Broadcast                   â”‚                â”‚
â”‚         â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                â”‚
â”‚         â”‚                                                           â”‚
â”‚         â”‚         Every 2 seconds (fallback)                       â”‚
â”‚         â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Stats Aggregation from Redis

| Redis Key | Type | Description |
|-----------|------|-------------|
| stats:urls_per_second | STRING | Current throughput |
| stats:queue_depth | STRING | Pending URL count |
| workers:active | SET | Active worker IDs |
| stats:failed_today | STRING | Daily error count |
| stats:total_crawled | STRING | Total pages fetched |
| stats:priority:high | STRING | High priority count |
| stats:priority:medium | STRING | Medium priority count |
| stats:priority:low | STRING | Low priority count |
| stats:throughput | SORTED SET | Sliding window (60s) |

### Worker Stats Publishing Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Worker   â”‚                    â”‚   Redis    â”‚                    â”‚ WebSocket  â”‚
â”‚            â”‚                    â”‚            â”‚                    â”‚  Clients   â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚                                 â”‚                                 â”‚
      â”‚ On startup:                     â”‚                                 â”‚
      â”‚ SADD workers:active             â”‚                                 â”‚
      â”‚ HSET worker:{id} status, time   â”‚                                 â”‚
      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                                 â”‚
      â”‚                                 â”‚                                 â”‚
      â”‚ On each crawl:                  â”‚                                 â”‚
      â”‚ INCR stats:total_crawled        â”‚                                 â”‚
      â”‚ INCR stats:failed_today (if err)â”‚                                 â”‚
      â”‚ ZADD stats:throughput timestamp â”‚                                 â”‚
      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                                 â”‚
      â”‚                                 â”‚                                 â”‚
      â”‚ PUBLISH crawler:stats {...}     â”‚                                 â”‚
      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                                 â”‚
      â”‚                                 â”‚ Broadcast to                    â”‚
      â”‚                                 â”‚ all clients                     â”‚
      â”‚                                 â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
      â”‚                                 â”‚                                 â”‚
      â”‚ Heartbeat every 5s:             â”‚                                 â”‚
      â”‚ Calculate URLs/sec from window  â”‚                                 â”‚
      â”‚ Update queue depth              â”‚                                 â”‚
      â”‚ EXPIRE worker:{id} 30s          â”‚                                 â”‚
      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                                 â”‚
```

### Frontend WebSocket Hook

| State | Description |
|-------|-------------|
| wsRef | WebSocket instance reference |
| reconnectTimeoutRef | Auto-reconnect timer |
| connected | Connection status for UI |

| Event | Handler |
|-------|---------|
| onopen | Set connected=true, clear reconnect timer |
| onmessage | Parse JSON, update stats store |
| onclose | Set connected=false, schedule reconnect (3s) |
| onerror | Log error, close connection |

---

## ğŸ—ï¸ Deep Dive: Domain Management Flow (6 minutes)

### Domain Update Sequence

```
Dashboard                API Server               Redis              PostgreSQL
    â”‚                        â”‚                      â”‚                     â”‚
    â”‚  PATCH /domains/foo    â”‚                      â”‚                     â”‚
    â”‚  {crawlDelayMs: 2000}  â”‚                      â”‚                     â”‚
    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                      â”‚                     â”‚
    â”‚                        â”‚                      â”‚                     â”‚
    â”‚                        â”‚  Validate with       â”‚                     â”‚
    â”‚                        â”‚  Zod schema          â”‚                     â”‚
    â”‚                        â”‚                      â”‚                     â”‚
    â”‚                        â”‚  SET crawldelay:foo  â”‚                     â”‚
    â”‚                        â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  â”‚                     â”‚
    â”‚                        â”‚                      â”‚                     â”‚
    â”‚                        â”‚  UPDATE domains      â”‚                     â”‚
    â”‚                        â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚
    â”‚                        â”‚                      â”‚                     â”‚
    â”‚                        â”‚  PUBLISH domain:update                     â”‚
    â”‚                        â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  â”‚                     â”‚
    â”‚                        â”‚                      â”‚                     â”‚
    â”‚  200 OK {domain}       â”‚                      â”‚                     â”‚
    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                      â”‚                     â”‚
    â”‚                        â”‚                      â”‚                     â”‚
    â”‚  WebSocket: domain     â”‚                      â”‚                     â”‚
    â”‚  update notification   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚                     â”‚
    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                      â”‚                     â”‚
```

### Dual-Write Strategy

Updates go to both Redis (immediate worker effect) and PostgreSQL (persistence):

| Update Type | Redis Action | PostgreSQL Action |
|-------------|--------------|-------------------|
| crawlDelayMs | SET crawldelay:{domain} | UPDATE domains SET crawl_delay |
| isBlocked=true | SADD blocked_domains | UPDATE domains SET is_blocked |
| isBlocked=false | SREM blocked_domains | UPDATE domains SET is_blocked |

Workers check Redis first for rate limits, ensuring immediate effect of dashboard changes.

---

## âš ï¸ Error Handling Across the Stack (4 minutes)

### Backend Error Response Format

| Field | Type | Description |
|-------|------|-------------|
| error | string | Human-readable message |
| code | string | Machine-readable error code |
| details | object | Field-specific errors (validation) |
| stack | string | Stack trace (dev only) |

### Error Code Catalog

| Code | HTTP Status | Scenario |
|------|-------------|----------|
| VALIDATION_ERROR | 400 | Invalid request data |
| NOT_FOUND | 404 | Resource doesn't exist |
| RATE_LIMITED | 429 | Too many requests |
| INTERNAL_ERROR | 500 | Unexpected server error |

### Frontend Error Handling Layers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Application Root                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Error Boundary (React)                        â”‚  â”‚
â”‚  â”‚  - Catches render errors                                   â”‚  â”‚
â”‚  â”‚  - Shows fallback UI                                       â”‚  â”‚
â”‚  â”‚  - Logs to error tracking                                  â”‚  â”‚
â”‚  â”‚  - Offers page reload                                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Toast Notification System                     â”‚  â”‚
â”‚  â”‚  - API error display                                       â”‚  â”‚
â”‚  â”‚  - Auto-dismiss after 5 seconds                            â”‚  â”‚
â”‚  â”‚  - Success/error/warning variants                          â”‚  â”‚
â”‚  â”‚  - Queue multiple toasts                                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              API Client Layer                              â”‚  â”‚
â”‚  â”‚  - Parse error responses                                   â”‚  â”‚
â”‚  â”‚  - Throw typed errors                                      â”‚  â”‚
â”‚  â”‚  - Handle network failures                                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš–ï¸ Trade-offs and Alternatives (2 minutes)

| Decision | Chosen | Alternative | Rationale |
|----------|--------|-------------|-----------|
| Real-time Protocol | âœ… WebSocket | âŒ SSE | Bidirectional for future extensibility |
| Type Sharing | âœ… Shared folder | âŒ OpenAPI codegen | Simpler, no build step |
| Validation | âœ… Zod | âŒ io-ts | Better DX, TypeScript integration |
| State Updates | âœ… Zustand + WebSocket | âŒ React Query | More control over streaming data |
| Error Handling | âœ… Custom classes | âŒ HTTP Problem Details | Simpler implementation |

---

## ğŸš€ Future Enhancements

With more time, I would add:

1. **OpenAPI spec generation** - Auto-generate from Zod schemas for client codegen
2. **Optimistic updates** - Instant UI feedback for domain management
3. **Request retries** - Exponential backoff in API client
4. **GraphQL subscriptions** - Alternative real-time protocol
5. **End-to-end testing** - Playwright for critical user flows

---

## ğŸ“ Summary

"I've designed a distributed web crawler with full-stack integration:

1. **Shared TypeScript types** - API contract consistency across frontend and backend
2. **End-to-end URL flow** - Dashboard submission through worker processing
3. **Real-time WebSocket** - Streaming crawler stats with 2-second latency
4. **Domain management** - Immediate Redis updates for worker rate limits
5. **Consistent error handling** - Typed errors with toast notifications

The architecture prioritizes type safety and real-time visibility while maintaining clean separation between frontend and backend responsibilities."
